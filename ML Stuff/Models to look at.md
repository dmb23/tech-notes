
> Qwen 2.5 Coder by Alibaba - 0.5B / 1.5B / 3B / 7B / 14B/ 32B (Base + Instruct) Code generation LLMs, with 32B tackling giants like Gemnini 1.5 Pro, Claude Sonnet  
>  
 LLM2CLIP from [Microsoft AI](https://www.linkedin.com/company/microsoft-ai/) - Leverage LLMs to train ultra-powerful CLIP models! Boosts performance over the previous SOTA by ~17%  
>  
 Athene v2 Chat & Agent by [Nexusflow](https://www.linkedin.com/company/nexusflow-ai/) - SoTA general LLM fine-tuned from Qwen 2.5 72B excels at Chat + Function Calling/ JSON/ Agents  
>  
 Orca Agent Instruct by MSFT research - 1 million instruct pairs covering text editing, creative writing, coding, reading comprehension, etc - permissively licensed  
>  
 Ultravox by [Fixie.ai](https://www.linkedin.com/company/fixie-ai/) - 70B/ 8B model approaching GPT4o level, pick any LLM, train an adapter with Whisper as Audio Encoder  
>  
 JanusFlow 1.3 by DeepSeek - Next iteration of their Unified MultiModal LLM Janus with RectifiedFlow  
>  
 Common Corpus by [pleias](https://www.linkedin.com/company/pleias/) - 2,003,039,184,047 multilingual, commercially permissive and high quality tokens!  